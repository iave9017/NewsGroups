{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Ian/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle \n",
    "from structures import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import stem\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write pickle file back to dictionary \n",
    "toDict = open(r'index.pkl', 'rb')\n",
    "docTermIndex = pickle.load(toDict)\n",
    "toDict.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'cryptology or space or religion or politics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Pre-processing, Stemming, and Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cryptolog', 'polit', 'religion', 'space'], dtype='<U9')"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qlist = query.strip().split()\n",
    "#Remove stop words\n",
    "modified = [term for term in qlist if term not in stopwords.words('english')]\n",
    "\n",
    "EXPAND = False\n",
    "'''Expansion\n",
    "EXPAND = True\n",
    "for term in modified:\n",
    "    syns = wordnet.synsets(term) \n",
    "    for i in range(len(syns)):\n",
    "        #print(syns[i].lemmas()[0].name())\n",
    "        new.append(syns[i].lemmas()[0].name())\n",
    "'''''''''\n",
    "if EXPAND == False:\n",
    "    new = modified\n",
    "before_stem = np.unique(new)\n",
    "ps = stem.PorterStemmer()\n",
    "after_stem = [ps.stem(word) for word in before_stem]\n",
    "mQuery = np.unique(after_stem)\n",
    "mQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Index and return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read potentially relevant docs into matrix using tf*idf weights \n",
    "qMatrix = pd.DataFrame(np.zeros((0,len(mQuery))), columns = mQuery)\n",
    "\n",
    "for term in mQuery:\n",
    "    if term in docTermIndex.keys():\n",
    "        termInfo = docTermIndex.get(term)\n",
    "        for occurence in termInfo.occList:\n",
    "            if occurence.docID not in qMatrix.index:\n",
    "                toAppend = pd.Series(np.zeros(len(qMatrix.columns)), index = qMatrix.columns, name = occurence.docID)\n",
    "                toAppend[term] = occurence.count * termInfo.idf\n",
    "                qMatrix = qMatrix.append(toAppend)\n",
    "            else:\n",
    "                qMatrix.loc[occurence.docID,term] = occurence.count * termInfo.idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute tfxidf vector of query \n",
    "q_vect = [docTermIndex.get(term).idf for term in qMatrix.columns]\n",
    "\n",
    "#Get cosine similarities for query \n",
    "matrix_norm = np.array([np.linalg.norm(qMatrix.iloc[i]) for i in range(len(qMatrix))])\n",
    "q_norm = np.linalg.norm(q_vect)\n",
    "sims = np.dot(qMatrix,q_vect)/(matrix_norm * q_norm)\n",
    "dists = 1 - sims\n",
    "idx = np.argsort(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_docs = qMatrix.iloc[idx[:10]].index \n",
    "classes = pd.read_csv('classes.csv',index_col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----0: File 15694 in folder sci.crypt-----\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "I could go on, but I'm sure you see my point.  I'm a single person,\n",
      "but I react differently on different groups (admittedly, in part\n",
      "because I'm a contrarian you always shouts \"but, on the other hand\n",
      "---------------------------------------------\n",
      "\n",
      "----1: File 15243 in folder sci.crypt-----\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "l this mathematically?\n",
      "* Why is the one-time pad secure?\n",
      "* What's a ciphertext-only attack?\n",
      "* What's a known-plaintext attack?\n",
      "* What's a chosen-plaintext attack?\n",
      "* In mathematical terms, what can you\n",
      "---------------------------------------------\n",
      "\n",
      "----2: File 15248 in folder sci.crypt-----\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      " analytical reasoning, application of mathematical tools, pattern\n",
      "  finding, patience, determination, and luck. The best available\n",
      "  textbooks on the subject are the Military Cryptanalytics series\n",
      "  [\n",
      "---------------------------------------------\n",
      "\n",
      "----3: File 15255 in folder sci.crypt-----\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      " laws surrounding cryptographic export, what\n",
      "  people think about those laws, and many other complex issues which\n",
      "  go beyond the scope of technical groups like sci.crypt. Make sure to\n",
      "  consult your \n",
      "---------------------------------------------\n",
      "\n",
      "----4: File 15588 in folder sci.crypt-----\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "stration fee, may be accepted if space \n",
      "is available, but there are NO GUARANTEES. To register, fill out the attached \n",
      "registration form and return to the address on the form along with payment in \n",
      "fu\n",
      "---------------------------------------------\n",
      "\n",
      "----5: File 15246 in folder sci.crypt-----\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      " design of substitution-\n",
      "          permutation encryption networks. IEEE Trans. Information\n",
      "          Theory, 28(10), 747--753, 1978.\n",
      "  [KIN78] P. Kinnucan, Data encryption gurus: Tuchman and Meyer.\n",
      " \n",
      "---------------------------------------------\n",
      "\n",
      "----6: File 15900 in folder sci.crypt-----\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "ith a chosen-\n",
      "plaintext attack using 1500 different encryptions.  Khafre with 24 rounds\n",
      "can be broken with the same attack using 2^53 different encryptions.\n",
      "(There are probably more efficient differen\n",
      "---------------------------------------------\n",
      "\n",
      "----7: File 15884 in folder sci.crypt-----\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "e: $f(x,s_1)$ = $f(x,s_2)$. Their well-thought approach\n",
      "exploits structural properties of the collision function to find \n",
      "a pseudocollision in about $2^{16}$ operations, much less than one\n",
      "would expec\n",
      "---------------------------------------------\n",
      "\n",
      "----8: File 15854 in folder sci.crypt-----\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      " I would be interested in general discussions and math also.\n",
      "\n",
      "I hope to have some foriegn correspondants so that we can test the response time of the\n",
      "\"men in the suits\" I've been hearing so much about\n",
      "---------------------------------------------\n",
      "\n",
      "----9: File 15849 in folder sci.crypt-----\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "nch\n",
      "\n",
      "\n",
      "             SESSION 7 : DIGITAL SIGNATURES\n",
      "             ------------------------------\n",
      "             Chair: C. Schnorr\n",
      "\n",
      "14.00-14.30  Practical and Provable Secure Release of a Secret and Exchang\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, path in enumerate(user_docs):\n",
    "    parts = path.split('/')\n",
    "    group = parts[1]\n",
    "    file = parts[2]\n",
    "    print('----{}: File {} in folder {}-----\\n'.format(i,file,group))\n",
    "    with open(path, 'r', errors='ignore') as myfile:\n",
    "        data = myfile.read()\n",
    "        art = data\n",
    "        ind = art.find('\\n\\n')\n",
    "        art = art[ind+2:]\n",
    "        #If article(and not post), re-index again to get rid of tags\n",
    "        if art[0:10].find('archive') != -1:\n",
    "            ind = art.find('\\n\\n')\n",
    "            art = art[ind+2:]\n",
    "        mid = len(art)//2\n",
    "        midmid = mid//2\n",
    "        print('---------------------------------------------\\n')\n",
    "        print(art[mid:mid+200])\n",
    "        print('---------------------------------------------\\n')\n",
    "        #print(art[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>docID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>61059</td>\n",
       "      <td>3880</td>\n",
       "      <td>20_newsgroups/comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61059</td>\n",
       "      <td>14408</td>\n",
       "      <td>20_newsgroups/sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                   class\n",
       "docID                                                    \n",
       "61059        3880  20_newsgroups/comp.sys.ibm.pc.hardware\n",
       "61059       14408                 20_newsgroups/sci.space"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
